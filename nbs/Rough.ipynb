{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torchtext\n",
    "import pickle\n",
    "import gensim\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from fastai.text import *\n",
    "from helpers import TextTransform, SearchEngineDataset, pad_collate\n",
    "from fastai.layers import Flatten\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from models import WideResNet, WideResNetEmbedding, WideResNetParallel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_pool5 = nn.AdaptiveAvgPool2d((5, 5))\n",
    "avg_pool6 = nn.AdaptiveAvgPool2d((6, 6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_pool5 = nn.AdaptiveMaxPool2d((5, 5))\n",
    "max_pool6 = nn.AdaptiveMaxPool2d((6, 6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_1x1 = torch.Tensor([[[1.]]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_1x2 = torch.Tensor([[[1., 1.], [2., 2.]]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1., 1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1., 1.]]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_pool5(x_1x1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1., 1., 1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1., 1., 1.]]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_pool6(x_1x1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1., 1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1., 1.]]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_pool5(x_1x1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1., 1., 1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1., 1., 1.]]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_pool6(x_1x1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n",
       "         [1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n",
       "         [1.5000, 1.5000, 1.5000, 1.5000, 1.5000],\n",
       "         [2.0000, 2.0000, 2.0000, 2.0000, 2.0000],\n",
       "         [2.0000, 2.0000, 2.0000, 2.0000, 2.0000]]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_pool5(x_1x2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1., 1., 1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1., 1., 1.],\n",
       "         [2., 2., 2., 2., 2., 2.],\n",
       "         [2., 2., 2., 2., 2., 2.],\n",
       "         [2., 2., 2., 2., 2., 2.]]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_pool6(x_1x2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1., 1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1., 1.],\n",
       "         [2., 2., 2., 2., 2.],\n",
       "         [2., 2., 2., 2., 2.],\n",
       "         [2., 2., 2., 2., 2.]]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_pool5(x_1x2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1., 1., 1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1., 1., 1.],\n",
       "         [2., 2., 2., 2., 2., 2.],\n",
       "         [2., 2., 2., 2., 2., 2.],\n",
       "         [2., 2., 2., 2., 2., 2.]]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_pool6(x_1x2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "itos = pickle.load(open('../../data/train_lm_data/itos.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['xxunk',\n",
       " 'xxpad',\n",
       " 'xxbos',\n",
       " 'xxfld',\n",
       " 'xxmaj',\n",
       " 'xxup',\n",
       " 'xxrep',\n",
       " 'xxwrep',\n",
       " '.',\n",
       " 'the',\n",
       " ',',\n",
       " 'of',\n",
       " 'and',\n",
       " 'a',\n",
       " 'to',\n",
       " '1',\n",
       " 'in',\n",
       " 'is',\n",
       " 'for',\n",
       " '-',\n",
       " ')',\n",
       " '(',\n",
       " 'or',\n",
       " 'that',\n",
       " 'are',\n",
       " 'you',\n",
       " 'as',\n",
       " 'it',\n",
       " 'on',\n",
       " ':',\n",
       " 'with',\n",
       " 'your',\n",
       " 'by',\n",
       " 'from',\n",
       " 'an',\n",
       " 'be',\n",
       " 'can',\n",
       " 'this',\n",
       " 'at',\n",
       " \"'s\",\n",
       " 'have',\n",
       " 'was',\n",
       " '$',\n",
       " 'not',\n",
       " '2',\n",
       " '/',\n",
       " 'if',\n",
       " 'one',\n",
       " 'which',\n",
       " 'will',\n",
       " 'more',\n",
       " 'has',\n",
       " ';',\n",
       " 'but',\n",
       " 'also',\n",
       " 'i',\n",
       " 'they',\n",
       " 'when',\n",
       " 'most',\n",
       " '3',\n",
       " 'all',\n",
       " 'may',\n",
       " 'about',\n",
       " 'other',\n",
       " 'than',\n",
       " 'time',\n",
       " 'used',\n",
       " '’s',\n",
       " 'there',\n",
       " 'up',\n",
       " 'their',\n",
       " 'do',\n",
       " 'first',\n",
       " 'some',\n",
       " 'its',\n",
       " 'two',\n",
       " 'new',\n",
       " 'use',\n",
       " 'how',\n",
       " 'what',\n",
       " '4',\n",
       " 'into',\n",
       " 'name',\n",
       " 'we',\n",
       " '%',\n",
       " 'who',\n",
       " 'people',\n",
       " 'only',\n",
       " 'years',\n",
       " 'per',\n",
       " 'average',\n",
       " \"'\",\n",
       " 'so',\n",
       " 'out',\n",
       " 'these',\n",
       " 'between',\n",
       " 'many',\n",
       " 'after',\n",
       " 'blood',\n",
       " 'such',\n",
       " 'year',\n",
       " 'like',\n",
       " 'water',\n",
       " 'his',\n",
       " 'he',\n",
       " 'any',\n",
       " 'body',\n",
       " 'over',\n",
       " 'number',\n",
       " '5',\n",
       " 'get',\n",
       " 'day',\n",
       " 'no',\n",
       " 'our',\n",
       " 'called',\n",
       " 'states',\n",
       " 'been',\n",
       " 'state',\n",
       " 'make',\n",
       " 'cost',\n",
       " 'each',\n",
       " 'system',\n",
       " '10',\n",
       " 'see',\n",
       " '?',\n",
       " '“',\n",
       " 'high',\n",
       " '”',\n",
       " 'were',\n",
       " 'then',\n",
       " 'just',\n",
       " 'should',\n",
       " 'through',\n",
       " 'known',\n",
       " 'does',\n",
       " \"n't\",\n",
       " 'world',\n",
       " 'information',\n",
       " 'united',\n",
       " 'long',\n",
       " 'part',\n",
       " 'need',\n",
       " 'usually',\n",
       " 'common',\n",
       " 'them',\n",
       " 'days',\n",
       " 'during',\n",
       " 'type',\n",
       " 'where',\n",
       " 'well',\n",
       " 'while',\n",
       " 'because',\n",
       " 'take',\n",
       " 'would',\n",
       " '!',\n",
       " 'often',\n",
       " 'my',\n",
       " 'area',\n",
       " 'much',\n",
       " 'very',\n",
       " 'best',\n",
       " 'city',\n",
       " 'form',\n",
       " 'made',\n",
       " 'county',\n",
       " 'before',\n",
       " 'different',\n",
       " '...',\n",
       " 'three',\n",
       " 'work',\n",
       " 'around',\n",
       " '6',\n",
       " 'found',\n",
       " 'home',\n",
       " 'cause',\n",
       " 'had',\n",
       " '–',\n",
       " 'hours',\n",
       " 'both',\n",
       " 'same',\n",
       " 'age',\n",
       " 'cells',\n",
       " 'food',\n",
       " 'include',\n",
       " 'help',\n",
       " 'find',\n",
       " 'health',\n",
       " 'her',\n",
       " 'person',\n",
       " 'small',\n",
       " 'way',\n",
       " 'including',\n",
       " 'disease',\n",
       " 'example',\n",
       " 'american',\n",
       " '&',\n",
       " 'life',\n",
       " 'based',\n",
       " 'even',\n",
       " 'symptoms',\n",
       " '—',\n",
       " 'us',\n",
       " 'however',\n",
       " 'back',\n",
       " 'using',\n",
       " 'good',\n",
       " 'under',\n",
       " 'pain',\n",
       " 'right',\n",
       " 'now',\n",
       " 'place',\n",
       " 'heart',\n",
       " 'here',\n",
       " 'less',\n",
       " 'being',\n",
       " 'definition',\n",
       " 'within',\n",
       " 'skin',\n",
       " 'minutes',\n",
       " 'service',\n",
       " 'term',\n",
       " 'she',\n",
       " 'tax',\n",
       " 'must',\n",
       " 'u.s.',\n",
       " 'below',\n",
       " 'every',\n",
       " 'down',\n",
       " 'means',\n",
       " 'free',\n",
       " 'meaning',\n",
       " '…',\n",
       " 'temperature',\n",
       " 'last',\n",
       " '7',\n",
       " 'data',\n",
       " '20',\n",
       " 'side',\n",
       " 'process',\n",
       " '8',\n",
       " 'rate',\n",
       " 'old',\n",
       " 'large',\n",
       " 'top',\n",
       " 'located',\n",
       " 'company',\n",
       " '°',\n",
       " 'amount',\n",
       " 'those',\n",
       " 'important',\n",
       " 'range',\n",
       " 'another',\n",
       " 'family',\n",
       " 'know',\n",
       " 'types',\n",
       " 'test',\n",
       " 'cell',\n",
       " 'medical',\n",
       " 'according',\n",
       " 'total',\n",
       " 'pay',\n",
       " 'business',\n",
       " 'salary',\n",
       " 'energy',\n",
       " 'want',\n",
       " 'low',\n",
       " 'group',\n",
       " 'off',\n",
       " 'size',\n",
       " '30',\n",
       " '12',\n",
       " 'since',\n",
       " 'level',\n",
       " 'go',\n",
       " 'set',\n",
       " 'english',\n",
       " 'until',\n",
       " 'full',\n",
       " '15',\n",
       " 'percent',\n",
       " ']',\n",
       " 'four',\n",
       " 'care',\n",
       " 'months',\n",
       " 'population',\n",
       " 'could',\n",
       " 'miles',\n",
       " 'price',\n",
       " 'causes',\n",
       " 'great',\n",
       " 'school',\n",
       " 'north',\n",
       " 'air',\n",
       " 'without',\n",
       " 'following',\n",
       " 'white',\n",
       " 'available',\n",
       " 'word',\n",
       " 'national',\n",
       " 'c',\n",
       " 'few',\n",
       " 'period',\n",
       " 'end',\n",
       " 'answer',\n",
       " 'feet',\n",
       " '[',\n",
       " 'weight',\n",
       " 'general',\n",
       " 'second',\n",
       " 'costs',\n",
       " '100',\n",
       " 'million',\n",
       " 'times',\n",
       " 'list',\n",
       " 'lower',\n",
       " 'south',\n",
       " 'code',\n",
       " 'oil',\n",
       " 'click',\n",
       " 'change',\n",
       " 'n’t',\n",
       " 'red',\n",
       " 'several',\n",
       " '..',\n",
       " 'baby',\n",
       " 'start',\n",
       " 'services',\n",
       " 'least',\n",
       " 'treatment',\n",
       " 'order',\n",
       " 'children',\n",
       " '--',\n",
       " 'weeks',\n",
       " 'pressure',\n",
       " 'square',\n",
       " 'normal',\n",
       " 'still',\n",
       " 'month',\n",
       " 'muscle',\n",
       " 'keep',\n",
       " 'hour',\n",
       " 'weather',\n",
       " 'due',\n",
       " 'history',\n",
       " 'caused',\n",
       " 'human',\n",
       " '=',\n",
       " 'show',\n",
       " 'light',\n",
       " '50',\n",
       " 'check',\n",
       " 'add',\n",
       " 'point',\n",
       " 'early',\n",
       " 'own',\n",
       " 'earth',\n",
       " 'calories',\n",
       " 'law',\n",
       " 'born',\n",
       " 'above',\n",
       " 'related',\n",
       " 'women',\n",
       " 'largest',\n",
       " 'too',\n",
       " 'job',\n",
       " 'center',\n",
       " 'main',\n",
       " 'local',\n",
       " 'live',\n",
       " 'single',\n",
       " 'little',\n",
       " 'provide',\n",
       " 'depending',\n",
       " 'sometimes',\n",
       " 'look',\n",
       " 'typically',\n",
       " 'credit',\n",
       " 'program',\n",
       " 'experience',\n",
       " 'protein',\n",
       " 'power',\n",
       " 'open',\n",
       " 'higher',\n",
       " 'child',\n",
       " 'major',\n",
       " 'might',\n",
       " 'once',\n",
       " 'become',\n",
       " 'specific',\n",
       " 'page',\n",
       " 'generally',\n",
       " 'products',\n",
       " 'brain',\n",
       " 'income',\n",
       " \"'re\",\n",
       " 'value',\n",
       " 'foods',\n",
       " 'standard',\n",
       " 'control',\n",
       " 'f',\n",
       " 'week',\n",
       " 'heat',\n",
       " 'country',\n",
       " 'office',\n",
       " 'line',\n",
       " 'non',\n",
       " 'five',\n",
       " 'fat',\n",
       " 'something',\n",
       " 'infection',\n",
       " 'plant',\n",
       " 'either',\n",
       " 'degrees',\n",
       " 'given',\n",
       " 'public',\n",
       " 'levels',\n",
       " 'left',\n",
       " 'government',\n",
       " 'current',\n",
       " 'house',\n",
       " '2015',\n",
       " '9',\n",
       " 'color',\n",
       " 'sugar',\n",
       " 'making',\n",
       " '|',\n",
       " '+',\n",
       " 'doctor',\n",
       " 'conditions',\n",
       " 'cancer',\n",
       " 'act',\n",
       " 'result',\n",
       " 'certain',\n",
       " 'today',\n",
       " 'next',\n",
       " 'date',\n",
       " 'account',\n",
       " 'although',\n",
       " 'car',\n",
       " 'along',\n",
       " 'real',\n",
       " 'natural',\n",
       " 'degree',\n",
       " 'half',\n",
       " 'social',\n",
       " 'words',\n",
       " 'give',\n",
       " 'insurance',\n",
       " 'come',\n",
       " 'did',\n",
       " 'file',\n",
       " 'popular',\n",
       " 'said',\n",
       " 'me',\n",
       " '25',\n",
       " 'surface',\n",
       " 'foot',\n",
       " 'better',\n",
       " 'species',\n",
       " 'war',\n",
       " 'black',\n",
       " 'condition',\n",
       " 'mean',\n",
       " 'having',\n",
       " 'function',\n",
       " 'series',\n",
       " 'risk',\n",
       " 'benefits',\n",
       " 'things',\n",
       " 'x',\n",
       " 'york',\n",
       " 'season',\n",
       " 'parts',\n",
       " 'america',\n",
       " 'effects',\n",
       " 'always',\n",
       " 'location',\n",
       " 'problems',\n",
       " 'case',\n",
       " 'property',\n",
       " 'language',\n",
       " 'gas',\n",
       " 'considered',\n",
       " 'report',\n",
       " 'president',\n",
       " 'increase',\n",
       " 'online',\n",
       " 'possible',\n",
       " 'acid',\n",
       " 'commonly',\n",
       " 'university',\n",
       " 'money',\n",
       " 'federal',\n",
       " 'plan',\n",
       " 'living',\n",
       " 'short',\n",
       " 'makes',\n",
       " 'especially',\n",
       " 'product',\n",
       " 'plants',\n",
       " 'site',\n",
       " 'support',\n",
       " 'central',\n",
       " 'phone',\n",
       " 'computer',\n",
       " 'annual',\n",
       " 'source',\n",
       " 'comes',\n",
       " 'inches',\n",
       " 'call',\n",
       " '2016',\n",
       " 'together',\n",
       " 'contains',\n",
       " 'quality',\n",
       " 'similar',\n",
       " 'areas',\n",
       " '18',\n",
       " 'learn',\n",
       " 'contact',\n",
       " 'takes',\n",
       " 'land',\n",
       " 'search',\n",
       " '0',\n",
       " 'includes',\n",
       " 'mg',\n",
       " 'daily',\n",
       " 'california',\n",
       " 'approximately',\n",
       " 'sure',\n",
       " 'please',\n",
       " 'view',\n",
       " 'loss',\n",
       " 'results',\n",
       " 'research',\n",
       " '*',\n",
       " 'others',\n",
       " 'eye',\n",
       " '#',\n",
       " 'head',\n",
       " '40',\n",
       " 'required',\n",
       " 'though',\n",
       " 'put',\n",
       " 'read',\n",
       " 'drug',\n",
       " '16',\n",
       " 'tissue',\n",
       " 'bacteria',\n",
       " 'complete',\n",
       " '24',\n",
       " 'chemical',\n",
       " 'needs',\n",
       " 'occur',\n",
       " 'terms',\n",
       " 'six',\n",
       " '2010',\n",
       " 'class',\n",
       " '2014',\n",
       " 'eat',\n",
       " 'away',\n",
       " 'dna',\n",
       " 'whether',\n",
       " 'provides',\n",
       " 'think',\n",
       " 'unit',\n",
       " 'study',\n",
       " 'occurs',\n",
       " 'patients',\n",
       " 'able',\n",
       " '14',\n",
       " 'security',\n",
       " 'green',\n",
       " 'various',\n",
       " 'physical',\n",
       " '2017',\n",
       " 'changes',\n",
       " 'why',\n",
       " 'cases',\n",
       " 'lot',\n",
       " 'forms',\n",
       " 'students',\n",
       " 'length',\n",
       " 'west',\n",
       " 'diet',\n",
       " '11',\n",
       " 'uses',\n",
       " 'against',\n",
       " 'longer',\n",
       " 'variety',\n",
       " 'associated',\n",
       " 'ca',\n",
       " 'near',\n",
       " 'hair',\n",
       " 'individual',\n",
       " 'g',\n",
       " 'cold',\n",
       " 'run',\n",
       " 'later',\n",
       " 'enough',\n",
       " 'dry',\n",
       " 'am',\n",
       " 'community',\n",
       " 'big',\n",
       " 'base',\n",
       " 'international',\n",
       " 'market',\n",
       " 'video',\n",
       " 'court',\n",
       " 'men',\n",
       " 'basic',\n",
       " 'education',\n",
       " 'hot',\n",
       " 'present',\n",
       " 'say',\n",
       " 'bone',\n",
       " 'b',\n",
       " 'dog',\n",
       " 'simple',\n",
       " '60',\n",
       " 'game',\n",
       " 'hard',\n",
       " 'card',\n",
       " 'growth',\n",
       " 'actually',\n",
       " 'oxygen',\n",
       " 'windows',\n",
       " 'easy',\n",
       " 'vary',\n",
       " 'going',\n",
       " 'management',\n",
       " 'liver',\n",
       " 'hand',\n",
       " 'death',\n",
       " 'man',\n",
       " 'college',\n",
       " 'eggs',\n",
       " 'etc',\n",
       " 'course',\n",
       " 'names',\n",
       " 'let',\n",
       " 'numbers',\n",
       " 'development',\n",
       " 'april',\n",
       " 'create',\n",
       " 'river',\n",
       " 'among',\n",
       " 'muscles',\n",
       " 'field',\n",
       " 'paid',\n",
       " 'space',\n",
       " 'm',\n",
       " 'him',\n",
       " 'july',\n",
       " 'someone',\n",
       " 'factors',\n",
       " 's',\n",
       " 'project',\n",
       " 'really',\n",
       " 'return',\n",
       " 'produced',\n",
       " 'whole',\n",
       " 'working',\n",
       " 'vitamin',\n",
       " \"'ll\",\n",
       " 'meat',\n",
       " 'material',\n",
       " 'remove',\n",
       " 'third',\n",
       " 'fact',\n",
       " 'access',\n",
       " 'highest',\n",
       " 'region',\n",
       " 'systems',\n",
       " 'island',\n",
       " 'east',\n",
       " 'town',\n",
       " 'inside',\n",
       " 'primary',\n",
       " 'across',\n",
       " 'step',\n",
       " '2013',\n",
       " 'produce',\n",
       " 'network',\n",
       " 'middle',\n",
       " 'sea',\n",
       " 'done',\n",
       " 'likely',\n",
       " 'taking',\n",
       " 'ago',\n",
       " 'treat',\n",
       " 'bank',\n",
       " '13',\n",
       " 'key',\n",
       " 'distance',\n",
       " 'park',\n",
       " 'records',\n",
       " 'texas',\n",
       " 'never',\n",
       " 'special',\n",
       " 'note',\n",
       " 'wide',\n",
       " '‘',\n",
       " 'january',\n",
       " 'almost',\n",
       " 'members',\n",
       " 'problem',\n",
       " 'sun',\n",
       " 'smaller',\n",
       " 'healthy',\n",
       " 'play',\n",
       " 'room',\n",
       " 'turn',\n",
       " 'blue',\n",
       " 'minimum',\n",
       " 'department',\n",
       " 'building',\n",
       " 'census',\n",
       " 'night',\n",
       " 'structure',\n",
       " 'french',\n",
       " 'fish',\n",
       " 'lead',\n",
       " 'works',\n",
       " 'news',\n",
       " 'move',\n",
       " 'music',\n",
       " 'training',\n",
       " 'salt',\n",
       " 'book',\n",
       " 'production',\n",
       " 'try',\n",
       " 'sign',\n",
       " 'km',\n",
       " 'sales',\n",
       " 'century',\n",
       " 'difference',\n",
       " 'animals',\n",
       " 'application',\n",
       " 'median',\n",
       " 'damage',\n",
       " '®',\n",
       " 'depends',\n",
       " 'fluid',\n",
       " 'share',\n",
       " 'march',\n",
       " 'additional',\n",
       " 'original',\n",
       " 'defined',\n",
       " 'chicken',\n",
       " 'team',\n",
       " 'contain',\n",
       " 'origin',\n",
       " 'store',\n",
       " 'table',\n",
       " 'feel',\n",
       " 'cover',\n",
       " 'love',\n",
       " 'helps',\n",
       " 'past',\n",
       " 'close',\n",
       " 'cut',\n",
       " 'milk',\n",
       " 'star',\n",
       " 'effect',\n",
       " 'nerve',\n",
       " 'address',\n",
       " 'role',\n",
       " 'receive',\n",
       " 'addition',\n",
       " 'john',\n",
       " 'severe',\n",
       " 'named',\n",
       " 'grow',\n",
       " 'choose',\n",
       " 'carbon',\n",
       " 'select',\n",
       " 'shows',\n",
       " 'financial',\n",
       " 'created',\n",
       " 'throughout',\n",
       " 'countries',\n",
       " 'e',\n",
       " 'rock',\n",
       " 'again',\n",
       " '’re',\n",
       " 'speed',\n",
       " 'website',\n",
       " 'legal',\n",
       " 'personal',\n",
       " 'prices',\n",
       " 'surgery',\n",
       " 'film',\n",
       " 'june',\n",
       " 'animal',\n",
       " 'professional',\n",
       " 'says',\n",
       " 'post',\n",
       " 'taken',\n",
       " 'stomach',\n",
       " 'pregnancy',\n",
       " 'apply',\n",
       " 'fee',\n",
       " 'grams',\n",
       " 'section',\n",
       " 'charge',\n",
       " 'looking',\n",
       " 'offer',\n",
       " 'record',\n",
       " 'ground',\n",
       " 'upper',\n",
       " 'travel',\n",
       " 'noun',\n",
       " 'force',\n",
       " 'simply',\n",
       " 'august',\n",
       " 'urine',\n",
       " 'medicine',\n",
       " 'ways',\n",
       " 'far',\n",
       " 'dictionary',\n",
       " 'map',\n",
       " 'refers',\n",
       " '2012',\n",
       " 'worth',\n",
       " 'getting',\n",
       " 'web',\n",
       " 'written',\n",
       " 'customer',\n",
       " 'examples',\n",
       " 'rates',\n",
       " '21',\n",
       " 'disorder',\n",
       " 'young',\n",
       " 'require',\n",
       " 'october',\n",
       " 'action',\n",
       " 'industry',\n",
       " 'position',\n",
       " 'tv',\n",
       " 'patient',\n",
       " 'labor',\n",
       " 'lake',\n",
       " 'outside',\n",
       " 'article',\n",
       " 'maximum',\n",
       " 'question',\n",
       " 'airport',\n",
       " 'birth',\n",
       " 'determine',\n",
       " 'larger',\n",
       " 'prevent',\n",
       " 'late',\n",
       " 'device',\n",
       " 'measure',\n",
       " 'referred',\n",
       " 'mass',\n",
       " 'particular',\n",
       " 'regular',\n",
       " 'seen',\n",
       " 'washington',\n",
       " '•',\n",
       " 'cook',\n",
       " 'content',\n",
       " 'member',\n",
       " 'infections',\n",
       " 'cup',\n",
       " 'became',\n",
       " 'activity',\n",
       " 'mouth',\n",
       " \"'ve\",\n",
       " 'programs',\n",
       " '17',\n",
       " 'florida',\n",
       " 'ever',\n",
       " 'thing',\n",
       " 'interest',\n",
       " 'upon',\n",
       " 'designed',\n",
       " 'tree',\n",
       " 'oven',\n",
       " 'september',\n",
       " 'summer',\n",
       " 'design',\n",
       " 'fiber',\n",
       " 'needed',\n",
       " 'female',\n",
       " 'salaries',\n",
       " 'diseases',\n",
       " 'reduce',\n",
       " 'probably',\n",
       " 'allow',\n",
       " 'active',\n",
       " 'movement',\n",
       " 'visit',\n",
       " 'drive',\n",
       " 'alcohol',\n",
       " 'pounds',\n",
       " 'companies',\n",
       " 'canada',\n",
       " 'materials',\n",
       " 'method',\n",
       " 'liquid',\n",
       " 'offers',\n",
       " 'released',\n",
       " 'iron',\n",
       " 'equal',\n",
       " 'party',\n",
       " 'directly',\n",
       " 'science',\n",
       " 'latin',\n",
       " 'version',\n",
       " 'wall',\n",
       " 'drugs',\n",
       " 'added',\n",
       " 'software',\n",
       " 'temperatures',\n",
       " 'buy',\n",
       " 'net',\n",
       " 'model',\n",
       " 'greek',\n",
       " 'features',\n",
       " 'height',\n",
       " '>',\n",
       " 'sex',\n",
       " 'front',\n",
       " 'joint',\n",
       " 'direct',\n",
       " 'story',\n",
       " 'brown',\n",
       " 'effective',\n",
       " 'tests',\n",
       " 'stay',\n",
       " 'typical',\n",
       " 'fall',\n",
       " 'box',\n",
       " 'flow',\n",
       " 'face',\n",
       " 'internet',\n",
       " 'affect',\n",
       " 'san',\n",
       " 'rights',\n",
       " 'rest',\n",
       " 'itself',\n",
       " 'allows',\n",
       " 'enter',\n",
       " 'layer',\n",
       " 'egg',\n",
       " 'medium',\n",
       " 'd',\n",
       " 'employees',\n",
       " 'cycle',\n",
       " 'formed',\n",
       " 'kind',\n",
       " '90',\n",
       " 'deep',\n",
       " 'official',\n",
       " 'strong',\n",
       " 'male',\n",
       " 'plus',\n",
       " 'follow',\n",
       " 'soil',\n",
       " 'cities',\n",
       " 'currently',\n",
       " 'true',\n",
       " 'questions',\n",
       " 'instead',\n",
       " 'signs',\n",
       " 'adults',\n",
       " 'guide',\n",
       " '2011',\n",
       " 'sleep',\n",
       " 'paper',\n",
       " 'files',\n",
       " 'requirements',\n",
       " 'practice',\n",
       " 'develop',\n",
       " 'kidney',\n",
       " 'clear',\n",
       " 'built',\n",
       " 'upload',\n",
       " 'older',\n",
       " 'safe',\n",
       " 'injury',\n",
       " 'fees',\n",
       " 'stop',\n",
       " 'vehicle',\n",
       " 'volume',\n",
       " 'listed',\n",
       " 'options',\n",
       " 'increased',\n",
       " 'serious',\n",
       " 'rather',\n",
       " 'organization',\n",
       " 'provided',\n",
       " 'adult',\n",
       " 'tell',\n",
       " 'points',\n",
       " 'ability',\n",
       " 'dogs',\n",
       " 'king',\n",
       " ...]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "itos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def loadGloveModel(gloveFile, d_emb):\n",
    "    print(\"Loading Glove Model\")\n",
    "    f = open(gloveFile,'r')\n",
    "    model = {}\n",
    "    for line in f:\n",
    "        elems = line.split()\n",
    "        vec = [float(n) for n in elems[-d_emb:]]\n",
    "        word = ' '.join(elems[:-d_emb])\n",
    "        model[word] = vec\n",
    "    print (\"Done.\",len(model),\" words loaded!\")\n",
    "    f.close()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Glove Model\n",
      "Done. 2195895  words loaded!\n"
     ]
    }
   ],
   "source": [
    "glove = loadGloveModel('../../../../../Pretrained/glove.840B.300d.txt', 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "itovecs = list()\n",
    "zero = np.zeros(300)\n",
    "for elem in itos:\n",
    "    if elem in glove:\n",
    "        itovecs.append(glove[elem])\n",
    "    else:\n",
    "        itovecs.append(zero)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "itovecs = np.array(itovecs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60002, 300)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "itovecs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('../../data/train_lm_data/itovecs.npy', itovecs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SearchEngineDataset(Dataset):\n",
    "    def __init__(self, csv_path, cols, transform=None):\n",
    "        self.query_key = 'query'\n",
    "        self.passage_key = 'passage'\n",
    "        self.qid_key = 'qid'\n",
    "        self.pid_key = 'pid'\n",
    "        self.label_key = 'label'        \n",
    "        self.data = pd.read_csv('../../data/data.tsv', sep='\\t', names=[self.qid_key,\n",
    "                                                                        self.query_key, \n",
    "                                                                        self.passage_key,\n",
    "                                                                        self.label_key,\n",
    "                                                                        self.pid_key])\n",
    "        self.data = self.data[cols]\n",
    "        self.data_len = len(self.data)\n",
    "        self.transform = transform\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.data_len\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        row = self.data.iloc[idx, :]\n",
    "        query = row[self.query_key]\n",
    "        passage = row[self.passage_key]\n",
    "        label = row[self.label_key]\n",
    "        if self.transform:\n",
    "            query = self.transform(query)\n",
    "            passage = self.transform(passage)\n",
    "        return ((query, passage), label)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/usr/local/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192, got 176\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "text_transform = TextTransform('../../data/train_lm_data/itos.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_dataset = SearchEngineDataset('../../data/data_sample.tsv',\n",
    "                                    ['query', 'passage', 'label'], \n",
    "                                     transform=text_transform.text_to_ints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = tokenizer.process_text('. what is a corporation?', base_tok)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[8, 79, 17, 13, 2040, 124]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab.numericalize(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[79, 17, 13, 2040]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_transform.text_to_ints('what is a corporation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "relu = nn.ReLU()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.0000, 3.0000, 0.0000, 7.8000])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.relu(torch.Tensor([1., 3., -1.5, 7.8]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[autoreload of helpers failed: Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.6/site-packages/IPython/extensions/autoreload.py\", line 245, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "  File \"/usr/local/lib/python3.6/site-packages/IPython/extensions/autoreload.py\", line 368, in superreload\n",
      "    module = reload(module)\n",
      "  File \"/usr/local/lib/python3.6/imp.py\", line 315, in reload\n",
      "    return importlib.reload(module)\n",
      "  File \"/usr/local/lib/python3.6/importlib/__init__.py\", line 166, in reload\n",
      "    _bootstrap._exec(spec, module)\n",
      "  File \"<frozen importlib._bootstrap>\", line 618, in _exec\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 674, in exec_module\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 781, in get_code\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 741, in source_to_code\n",
      "  File \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\n",
      "  File \"/media/saqib/ni/Projects/Microsoft/AI_Challenge_18/code/nbs/helpers.py\", line 47\n",
      "    padded_seqs =\n",
      "                 ^\n",
      "SyntaxError: invalid syntax\n",
      "]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.zeros(6, 18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [[1, 1], [2, 2], [3, 3]]\n",
    "b = [[4, 4, 4], [5, 5, 5], [6, 6, 6]]\n",
    "c = [7, 8, 9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(([1, 1], [4, 4, 4]), 7), (([2, 2], [5, 5, 5]), 8), (([3, 3], [6, 6, 6]), 9)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(zip(list(zip(a, b)), c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dl = DataLoader(search_dataset, batch_size=2, shuffle=True, num_workers=4, collate_fn=pad_collate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmbeddingModel(nn.Module):\n",
    "    def __init__(self, vocab_size, pretrained_wts_pth, emb_dim=300):\n",
    "        super().__init__()\n",
    "        self.emb = nn.Embedding(vocab_size, emb_dim)\n",
    "        # Intitialize embedding to GloVe weights\n",
    "        self.emb.weight.data.copy_(torch.from_numpy(np.load(pretrained_wts_pth)))\n",
    "        self.adap_avg_pool = nn.AdaptiveAvgPool2d((32, 32))\n",
    "        self.adap_max_pool = nn.AdaptiveMaxPool2d((32, 32))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        q = self.emb(x[0])\n",
    "        qap = self.adap_avg_pool(q)\n",
    "        qmp = self.adap_max_pool(q)\n",
    "        q = torch.cat([qap, qmp], dim=1)\n",
    "\n",
    "        p = self.emb(x[1]) \n",
    "        pap = self.adap_avg_pool(p)\n",
    "        pmp = self.adap_max_pool(p)\n",
    "        p = torch.cat([pap, pmp], dim=1)\n",
    "        \n",
    "        x = torch.cat([q, p], dim=2)\n",
    "        x = x.unsqueeze(1)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "wrnp = WideResNetParallel(60002, '../../data/train_lm_data/itovecs.npy', 300, n_grps=2, N=2, k=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WideResNetParallel(\n",
      "  (emb): Embedding(60002, 300)\n",
      "  (adap_avg_pool): AdaptiveAvgPool2d(output_size=(32, 32))\n",
      "  (adap_max_pool): AdaptiveMaxPool2d(output_size=(32, 32))\n",
      "  (qwrn): WideResNetOpen(\n",
      "    (features): Sequential(\n",
      "      (0): Conv2d(1, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (1): BasicBlock(\n",
      "        (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv1): Conv2d(16, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (drop): Dropout(p=0.3, inplace)\n",
      "        (bn2): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(80, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (shortcut): Sequential(\n",
      "          (0): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (1): ReLU(inplace)\n",
      "          (2): Conv2d(16, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "      )\n",
      "      (2): BasicBlock(\n",
      "        (bn1): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv1): Conv2d(80, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (drop): Dropout(p=0.3, inplace)\n",
      "        (bn2): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(80, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (3): BasicBlock(\n",
      "        (bn1): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv1): Conv2d(80, 160, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (drop): Dropout(p=0.3, inplace)\n",
      "        (bn2): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (shortcut): Sequential(\n",
      "          (0): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (1): ReLU(inplace)\n",
      "          (2): Conv2d(80, 160, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        )\n",
      "      )\n",
      "      (4): BasicBlock(\n",
      "        (bn1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv1): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (drop): Dropout(p=0.3, inplace)\n",
      "        (bn2): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (5): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (6): ReLU(inplace)\n",
      "      (7): AdaptiveAvgPool2d(output_size=1)\n",
      "      (8): Lambda()\n",
      "      (9): Linear(in_features=160, out_features=10, bias=True)\n",
      "    )\n",
      "  )\n",
      "  (pwrn): WideResNetOpen(\n",
      "    (features): Sequential(\n",
      "      (0): Conv2d(1, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (1): BasicBlock(\n",
      "        (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv1): Conv2d(16, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (drop): Dropout(p=0.3, inplace)\n",
      "        (bn2): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(80, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (shortcut): Sequential(\n",
      "          (0): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (1): ReLU(inplace)\n",
      "          (2): Conv2d(16, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "      )\n",
      "      (2): BasicBlock(\n",
      "        (bn1): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv1): Conv2d(80, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (drop): Dropout(p=0.3, inplace)\n",
      "        (bn2): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(80, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (3): BasicBlock(\n",
      "        (bn1): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv1): Conv2d(80, 160, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (drop): Dropout(p=0.3, inplace)\n",
      "        (bn2): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (shortcut): Sequential(\n",
      "          (0): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (1): ReLU(inplace)\n",
      "          (2): Conv2d(80, 160, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        )\n",
      "      )\n",
      "      (4): BasicBlock(\n",
      "        (bn1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv1): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (drop): Dropout(p=0.3, inplace)\n",
      "        (bn2): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (5): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (6): ReLU(inplace)\n",
      "      (7): AdaptiveAvgPool2d(output_size=1)\n",
      "      (8): Lambda()\n",
      "      (9): Linear(in_features=160, out_features=10, bias=True)\n",
      "    )\n",
      "  )\n",
      "  (linear): Linear(in_features=20, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(wrnp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20243297"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(p.numel() for p in wrnp.parameters() if p.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_model = EmbeddingModel(60002, '../../data/train_lm_data/itovecs.npy', emb_dim=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = next(iter(dl))\n",
    "out = wrnp(*x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 1])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.5234],\n",
       "        [0.5236]], grad_fn=<SigmoidBackward>)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv = nn.Conv2d(1, 2, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[-0.1640, -0.1776, -0.0973,  ..., -0.1322, -0.1137, -0.1232],\n",
       "          [-0.1640, -0.1776, -0.0973,  ..., -0.1121, -0.1115, -0.0635],\n",
       "          [-0.1734, -0.1580, -0.0890,  ..., -0.1330, -0.1117, -0.1017],\n",
       "          ...,\n",
       "          [-0.9917, -1.3308, -0.3863,  ..., -0.1118, -0.1118, -0.1118],\n",
       "          [-0.1118, -0.1118, -0.1118,  ..., -0.1118, -0.1118, -0.1118],\n",
       "          [-0.1118, -0.1118, -0.1118,  ..., -0.1118, -0.1118, -0.1118]],\n",
       "\n",
       "         [[ 0.4030,  0.2226,  0.3714,  ...,  0.3342,  0.3283,  0.2080],\n",
       "          [ 0.4030,  0.2226,  0.3714,  ...,  0.3437,  0.3010,  0.2197],\n",
       "          [ 0.4057,  0.2317,  0.3788,  ...,  0.2990,  0.2612,  0.2679],\n",
       "          ...,\n",
       "          [ 1.3058, -0.0430,  0.3647,  ...,  0.2921,  0.2921,  0.2921],\n",
       "          [ 0.2921,  0.2921,  0.2921,  ...,  0.2921,  0.2921,  0.2921],\n",
       "          [ 0.2921,  0.2921,  0.2921,  ...,  0.2921,  0.2921,  0.2921]]],\n",
       "\n",
       "\n",
       "        [[[-0.1455, -0.1613, -0.0935,  ..., -0.0876, -0.1411, -0.1232],\n",
       "          [-0.1455, -0.1613, -0.0935,  ..., -0.0974, -0.1188, -0.1142],\n",
       "          [-0.1459, -0.1438, -0.1159,  ..., -0.1522, -0.0677, -0.1016],\n",
       "          ...,\n",
       "          [-0.5470, -0.5682, -0.6335,  ..., -0.4634, -0.3871, -0.3781],\n",
       "          [-0.3505, -0.4425, -0.2127,  ..., -0.3691, -0.3367, -0.3021],\n",
       "          [-0.3505, -0.4425, -0.2127,  ..., -0.3898, -0.3452, -0.3213]],\n",
       "\n",
       "         [[ 0.3666,  0.2527,  0.3870,  ...,  0.2892,  0.3230,  0.2868],\n",
       "          [ 0.3666,  0.2527,  0.3870,  ...,  0.3027,  0.3175,  0.2629],\n",
       "          [ 0.3607,  0.2449,  0.3790,  ...,  0.3036,  0.3182,  0.3031],\n",
       "          ...,\n",
       "          [ 0.4160,  0.3370,  0.1908,  ...,  0.3251,  0.1088,  0.3463],\n",
       "          [ 0.5735,  0.1392,  0.4000,  ...,  0.1814,  0.2163,  0.3857],\n",
       "          [ 0.5735,  0.1392,  0.4000,  ...,  0.2290,  0.2330,  0.1503]]]],\n",
       "       grad_fn=<MkldnnConvolutionBackward>)"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "wrn = WideResNet(n_grps=3, N=4, k=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WideResNet(\n",
      "  (features): Sequential(\n",
      "    (0): Conv2d(1, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (1): BasicBlock(\n",
      "      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv1): Conv2d(16, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (drop): Dropout(p=0.3, inplace)\n",
      "      (bn2): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (shortcut): Sequential(\n",
      "        (0): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (1): ReLU(inplace)\n",
      "        (2): Conv2d(16, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (2): BasicBlock(\n",
      "      (bn1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv1): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (drop): Dropout(p=0.3, inplace)\n",
      "      (bn2): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (3): BasicBlock(\n",
      "      (bn1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv1): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (drop): Dropout(p=0.3, inplace)\n",
      "      (bn2): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (4): BasicBlock(\n",
      "      (bn1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv1): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (drop): Dropout(p=0.3, inplace)\n",
      "      (bn2): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (5): BasicBlock(\n",
      "      (bn1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv1): Conv2d(160, 320, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (drop): Dropout(p=0.3, inplace)\n",
      "      (bn2): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (shortcut): Sequential(\n",
      "        (0): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (1): ReLU(inplace)\n",
      "        (2): Conv2d(160, 320, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (6): BasicBlock(\n",
      "      (bn1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv1): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (drop): Dropout(p=0.3, inplace)\n",
      "      (bn2): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (7): BasicBlock(\n",
      "      (bn1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv1): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (drop): Dropout(p=0.3, inplace)\n",
      "      (bn2): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (8): BasicBlock(\n",
      "      (bn1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv1): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (drop): Dropout(p=0.3, inplace)\n",
      "      (bn2): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (9): BasicBlock(\n",
      "      (bn1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv1): Conv2d(320, 640, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (drop): Dropout(p=0.3, inplace)\n",
      "      (bn2): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (shortcut): Sequential(\n",
      "        (0): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (1): ReLU(inplace)\n",
      "        (2): Conv2d(320, 640, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (10): BasicBlock(\n",
      "      (bn1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv1): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (drop): Dropout(p=0.3, inplace)\n",
      "      (bn2): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (11): BasicBlock(\n",
      "      (bn1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv1): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (drop): Dropout(p=0.3, inplace)\n",
      "      (bn2): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (12): BasicBlock(\n",
      "      (bn1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv1): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (drop): Dropout(p=0.3, inplace)\n",
      "      (bn2): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (13): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (14): ReLU(inplace)\n",
      "    (15): AdaptiveAvgPool2d(output_size=1)\n",
      "    (16): Lambda()\n",
      "    (17): Linear(in_features=640, out_features=10, bias=True)\n",
      "    (18): Linear(in_features=10, out_features=1, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(wrn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.4598],\n",
       "        [0.4578]], grad_fn=<SigmoidBackward>)"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wrn(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Traceback (most recent call last):\n  File \"/usr/local/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 138, in _worker_loop\n    samples = collate_fn([dataset[i] for i in batch_indices])\n  File \"/media/saqib/ni/Projects/Microsoft/AI_Challenge_18/code/nbs/helpers.py\", line 59, in pad_collate\n    targets = torch.FloatTensor([item[1] for item in batch])\nValueError: too many dimensions 'str'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-0cb076d8ae46>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    635\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreorder_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    636\u001b[0m                 \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 637\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_next_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    638\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    639\u001b[0m     \u001b[0mnext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m__next__\u001b[0m  \u001b[0;31m# Python 2 compatibility\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_process_next_batch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    656\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_put_indices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    657\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mExceptionWrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 658\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_msg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    659\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    660\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Traceback (most recent call last):\n  File \"/usr/local/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 138, in _worker_loop\n    samples = collate_fn([dataset[i] for i in batch_indices])\n  File \"/media/saqib/ni/Projects/Microsoft/AI_Challenge_18/code/nbs/helpers.py\", line 59, in pad_collate\n    targets = torch.FloatTensor([item[1] for item in batch])\nValueError: too many dimensions 'str'\n"
     ]
    }
   ],
   "source": [
    "next(iter(dl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "blah = (x[0].cuda(), x[1].cuda())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = WideResNetEmbedding(60002, '/media/saqib/ni/Projects/Microsoft/AI_Challenge_18/data/train_lm_data/itovecs.npy', 300, 3, 3, 5 \n",
    "                           )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
